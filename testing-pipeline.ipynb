{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":4620664,"sourceType":"datasetVersion","datasetId":2663421},{"sourceId":6920046,"sourceType":"datasetVersion","datasetId":3973543},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7409757,"sourceType":"datasetVersion","datasetId":4309703},{"sourceId":7489386,"sourceType":"datasetVersion","datasetId":4332461}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:05:52.630002Z","iopub.execute_input":"2024-01-27T19:05:52.630417Z","iopub.status.idle":"2024-01-27T19:05:52.634590Z","shell.execute_reply.started":"2024-01-27T19:05:52.630384Z","shell.execute_reply":"2024-01-27T19:05:52.633687Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# !python --version  \n# Python 3.10.12","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:05:52.639966Z","iopub.execute_input":"2024-01-27T19:05:52.640484Z","iopub.status.idle":"2024-01-27T19:05:52.646406Z","shell.execute_reply.started":"2024-01-27T19:05:52.640451Z","shell.execute_reply":"2024-01-27T19:05:52.645363Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"from typing import Optional\nfrom datetime import datetime\n\nimport os\nimport pickle\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom collections import Counter\n\n!pip install /kaggle/input/pyspellchecker/pyspellchecker-0.8.0-py3-none-any.whl\nfrom spellchecker import SpellChecker\n\nimport spacy\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-27T19:05:52.647903Z","iopub.execute_input":"2024-01-27T19:05:52.648421Z","iopub.status.idle":"2024-01-27T19:06:24.090746Z","shell.execute_reply.started":"2024-01-27T19:05:52.648392Z","shell.execute_reply":"2024-01-27T19:06:24.089665Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/pyspellchecker/pyspellchecker-0.8.0-py3-none-any.whl\npyspellchecker is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Globals","metadata":{}},{"cell_type":"code","source":"CSV_INPUT_PATH = '/kaggle/input/llm-detect-ai-generated-text/test_essays.csv'\nINPUT_PATH = '/kaggle/input/'\nCATBOOST_PATH = '/kaggle/input/catboost/'","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.093322Z","iopub.execute_input":"2024-01-27T19:06:24.093699Z","iopub.status.idle":"2024-01-27T19:06:24.099874Z","shell.execute_reply.started":"2024-01-27T19:06:24.093665Z","shell.execute_reply":"2024-01-27T19:06:24.098683Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def printime():\n    now = datetime.now()\n    current_time = now.strftime(\"%H:%M:%S\")\n    print(\"Current Time =\", current_time)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.101270Z","iopub.execute_input":"2024-01-27T19:06:24.101598Z","iopub.status.idle":"2024-01-27T19:06:24.109969Z","shell.execute_reply.started":"2024-01-27T19:06:24.101570Z","shell.execute_reply":"2024-01-27T19:06:24.108822Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"def get_df_test():\n    X_test = pd.read_csv(CSV_INPUT_PATH)\n#     X_test['text'] = correct_spelling(X_test, 'text')\n    X_test['clean_text'] = clean_text(X_test)\n    return X_test","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.112944Z","iopub.execute_input":"2024-01-27T19:06:24.113635Z","iopub.status.idle":"2024-01-27T19:06:24.119797Z","shell.execute_reply.started":"2024-01-27T19:06:24.113593Z","shell.execute_reply":"2024-01-27T19:06:24.118775Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def correct_text_spelling(text):\n    spell = SpellChecker()\n    words = re.findall(r'\\b\\w+\\b', text)\n    misspelled = spell.unknown(words)\n    corrected_text = text\n    for word in misspelled:\n        if spell.correction(word):\n            corrected_text = corrected_text.replace(word, spell.correction(word))\n    return corrected_text\n\ndef correct_spelling(df, text_col: str = 'text') -> pd.DataFrame:\n    df_ = df.copy()\n    df_['corrected'] = df_[text_col].apply(correct_text_spelling)\n    return df_['corrected']","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.120872Z","iopub.execute_input":"2024-01-27T19:06:24.121366Z","iopub.status.idle":"2024-01-27T19:06:24.128844Z","shell.execute_reply.started":"2024-01-27T19:06:24.121315Z","shell.execute_reply":"2024-01-27T19:06:24.127709Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def get_corpus(df: pd.DataFrame, text_col: str = 'clean_text') -> list[str]:\n    return df[text_col].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.130300Z","iopub.execute_input":"2024-01-27T19:06:24.130641Z","iopub.status.idle":"2024-01-27T19:06:24.138447Z","shell.execute_reply.started":"2024-01-27T19:06:24.130599Z","shell.execute_reply":"2024-01-27T19:06:24.137578Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Text Cleaning and Features","metadata":{}},{"cell_type":"code","source":"# cleaned text\ndef clean_text(df: pd.DataFrame) -> pd.Series:\n    df_ = df.copy()\n    \n    df_['clean_text'] = (df_['text'].str.replace('\\n\\n', '') \n                                    .str.replace('\\'s', '')\n                                    .str.replace('[.,?!:;\\'\\\\\\\\\"]', '', regex=True)\n                                    .str.lower()\n                        )\n    \n    return df_['clean_text']","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.139383Z","iopub.execute_input":"2024-01-27T19:06:24.139681Z","iopub.status.idle":"2024-01-27T19:06:24.149122Z","shell.execute_reply.started":"2024-01-27T19:06:24.139648Z","shell.execute_reply":"2024-01-27T19:06:24.148079Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def tfidf(corpus: list[str], vectorizer: Optional[TfidfVectorizer] = None) -> [pd.DataFrame | tuple[pd.DataFrame, pd.DataFrame]]:\n    \n    if vectorizer:\n        M = vectorizer.transform(corpus)\n        return M\n    \n    else:\n        vectorizer = TfidfVectorizer(\n                                     lowercase=False,\n#                                      token_pattern = None,\n                                     sublinear_tf=True,\n                                     stop_words='english',\n                                     ngram_range=(3,5)\n                                    )\n        \n        M = vectorizer.fit_transform(corpus)\n        \n        return M, vectorizer ","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.150084Z","iopub.execute_input":"2024-01-27T19:06:24.150596Z","iopub.status.idle":"2024-01-27T19:06:24.159977Z","shell.execute_reply.started":"2024-01-27T19:06:24.150555Z","shell.execute_reply":"2024-01-27T19:06:24.158997Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def pos_feature(df: pd.DataFrame, text_col: str = 'clean_text') -> pd.DataFrame:\n    df_ = df.copy()\n    \n    nlp = spacy.load(\"en_core_web_sm\")\n\n    docs = [nlp(t) for t in df_[text_col]]\n    pos_tags = [[token.pos_ for token in doc] for doc in docs]\n    \n    df_['pos_tags'] = pos_tags\n    \n    df_['pos_text'] = df_['pos_tags'].apply(lambda x: ' '.join(x))\n    \n    df_['NOUN_count'] = df_['pos_text'].str.count('NOUN')\n    df_['VERB_count'] = df_['pos_text'].str.count('VERB')\n    df_['ADJ_count'] = df_['pos_text'].str.count('ADJ')\n    df_['ADV_count'] = df_['pos_text'].str.count('ADV')\n    df_['ADP_count'] = df_['pos_text'].str.count('ADP')\n    df_['PRON_count'] = df_['pos_text'].str.count('PRON')\n    df_['PROPN_count'] = df_['pos_text'].str.count('PROPN')\n    df_['PUNCT_count'] = df_['pos_text'].str.count('PUNCT')\n    df_['AUX_count'] = df_['pos_text'].str.count('AUX')\n    df_['NUM_count'] = df_['pos_text'].str.count('NUM')\n    df_['X_count'] = df_['pos_text'].str.count('X')\n    \n    df_ = df_.drop(columns=['pos_tags', 'pos_text'])\n    \n    return df_\n    \ndef stopwords_feature(df, text_col: str = 'clean_text') -> pd.DataFrame:\n    df_ = df.copy()\n    \n    stop_words = set(stopwords.words('english'))\n\n    def stopwords_counter_and_filter(row):\n        words = word_tokenize(row[text_col])\n        stopword_counter = sum(1 for w in words if w.lower() in stop_words)\n        filtered_text = ' '.join(w for w in words if w.lower() not in stop_words)\n        return stopword_counter, filtered_text\n\n    df_[['number_of_stopwords', 'filtered_text']] = df_.apply(stopwords_counter_and_filter, axis=1, result_type='expand')\n\n    return df_\n\ndef caps_to_periods_ratio_feature(df) -> pd.DataFrame:\n    df_ = df.copy()\n    \n    parentheses_count = df_['parentheses_count']\n    caps_count = df_['text'].str.count(r'[A-Z]')\n    df_['caps_to_periods_ratio'] = caps_count / parentheses_count.replace(0, 1) # replace 0 by 1 to avoid deviding by 0\n    \n    return df_","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.161713Z","iopub.execute_input":"2024-01-27T19:06:24.162141Z","iopub.status.idle":"2024-01-27T19:06:24.178302Z","shell.execute_reply.started":"2024-01-27T19:06:24.162103Z","shell.execute_reply":"2024-01-27T19:06:24.177321Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Feature Extraction","metadata":{}},{"cell_type":"code","source":"def feature_extraction(df, text_col: str = 'clean_text') -> pd.DataFrame:\n    \"\"\"\n    \n    Extracts text based features for column text_col\n    \n    \"\"\"\n    \n    df_ = df.copy()\n    \n    # text length\n    df_['num_of_words'] = (df_[text_col].str.replace('\\n\\n', '') # removing row\n                                .str.count(' ')+1)\n    # uniqe words per row\n    df_['text_vocab_size'] = df_[text_col].apply(lambda x : len(set(x.split())))\n    \n    df_['num_of_sentences'] = df_[text_col].str.count('\\.')\n    \n    df_['parentheses_count'] = df_['text'].str.count('\\(|\\)')\n    \n    df_['semicolon_count'] = df_['text'].str.count(';')\n\n    df_['hypen_count'] = df_['text'].str.count('-')\n    \n    df_['dash_count'] = df_['text'].str.count('—')\n    \n    df_['comma_count'] = df_['text'].str.count(',')\n    \n    df_['qm_count'] = df_['text'].str.count('\\?')\n    \n    df_['en_count'] = df_['text'].str.count('!')\n    \n    df_['apostrophe_count'] = df_['text'].str.count('’')\n    \n    df_['paragraph_count'] = df_['text'].str.count('\\n\\n')\n    \n    # extract POS features\n    df_ = pos_feature(df_, text_col)\n    \n    # df_ = stopwords_feature(df_, text_col)\n    \n    # count typos\n#     df_ = typos_count_feature(df_)\n\n    # calculate the ratio between the number of capital letters and periods\n    df_ = caps_to_periods_ratio_feature(df_)\n    \n    return df_","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.182457Z","iopub.execute_input":"2024-01-27T19:06:24.182864Z","iopub.status.idle":"2024-01-27T19:06:24.195265Z","shell.execute_reply.started":"2024-01-27T19:06:24.182829Z","shell.execute_reply":"2024-01-27T19:06:24.194138Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Loading pickles and CSVs","metadata":{}},{"cell_type":"code","source":"files = os.listdir(CATBOOST_PATH)\n\nfor file_name in files:\n    file_path = os.path.join(CATBOOST_PATH, file_name)\n    name, extension = os.path.splitext(file_name)\n    with open(file_path, 'rb') as file:\n        if extension == '.pickle':\n            globals()[name] = pickle.load(file)\n        elif extension == '.csv':\n            globals()[name] = pd.read_csv(file, index_col=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.196260Z","iopub.execute_input":"2024-01-27T19:06:24.196574Z","iopub.status.idle":"2024-01-27T19:06:24.285512Z","shell.execute_reply.started":"2024-01-27T19:06:24.196547Z","shell.execute_reply":"2024-01-27T19:06:24.284215Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Models by Feature Sets","metadata":{}},{"cell_type":"code","source":"def text_tfidf_models_test():\n    X_test = get_df_test()\n\n    cols = ['id', 'prompt_id']\n    X_test = X_test.drop(columns=cols)\n    \n    corpus_test = get_corpus(X_test)\n    tfidf_X_test = tfidf(corpus_test, text_tfidf_vectorizer)\n    tfidf_test_pred = text_tfidf_ensemble.predict_proba(tfidf_X_test)[:,1]\n    \n    return tfidf_test_pred","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.286650Z","iopub.execute_input":"2024-01-27T19:06:24.289539Z","iopub.status.idle":"2024-01-27T19:06:24.294729Z","shell.execute_reply.started":"2024-01-27T19:06:24.289503Z","shell.execute_reply":"2024-01-27T19:06:24.293726Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def pos_tfidf_models_test():\n    X_test = get_df_test()\n\n    # Extract pos related feature\n    nlp = spacy.load(\"en_core_web_sm\")\n    docs = [nlp(t) for t in X_test['clean_text']]\n    pos_tags = [[token.pos_ for token in doc] for doc in docs]\n    X_test['pos_tags'] = pos_tags\n    X_test['pos_text'] = X_test['pos_tags'].apply(lambda x: ' '.join(x))\n\n    cols = ['id', 'prompt_id']\n    X_test = X_test.drop(columns=cols)\n    \n    pos_corpus_test = get_corpus(X_test, text_col='pos_text')\n    pos_tfidf_X_test = tfidf(pos_corpus_test, pos_tfidf_vectorizer)\n    pos_test_pred = pos_tfidf_ensemble.predict_proba(pos_tfidf_X_test)[:,1]\n    \n    return pos_test_pred","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.296085Z","iopub.execute_input":"2024-01-27T19:06:24.296413Z","iopub.status.idle":"2024-01-27T19:06:24.309242Z","shell.execute_reply.started":"2024-01-27T19:06:24.296385Z","shell.execute_reply":"2024-01-27T19:06:24.308224Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def numeric_features_models_test():    \n    X_test = get_df_test()\n\n    # Extract numeric feature\n    X_test = feature_extraction(X_test, 'clean_text')\n\n    X_test_id = X_test['id']\n\n    cols = ['id', 'prompt_id', 'text','clean_text'] # 'pos_text'\n    X_test = X_test.drop(columns=cols)\n    \n    test_pred = num_ensemble.predict_proba(X_test)[:,1]\n    \n    return X_test_id, test_pred","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.310959Z","iopub.execute_input":"2024-01-27T19:06:24.311386Z","iopub.status.idle":"2024-01-27T19:06:24.319302Z","shell.execute_reply.started":"2024-01-27T19:06:24.311339Z","shell.execute_reply":"2024-01-27T19:06:24.318245Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Execution and Analysis","metadata":{}},{"cell_type":"code","source":"printime()\ntfidf_test_pred = text_tfidf_models_test()\nprintime()\npos_test_pred = pos_tfidf_models_test()\nprintime()\nX_test_id, test_pred = numeric_features_models_test()\nprintime()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:24.320546Z","iopub.execute_input":"2024-01-27T19:06:24.320885Z","iopub.status.idle":"2024-01-27T19:06:26.092467Z","shell.execute_reply.started":"2024-01-27T19:06:24.320855Z","shell.execute_reply":"2024-01-27T19:06:26.091196Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Current Time = 19:06:24\nCurrent Time = 19:06:24\nCurrent Time = 19:06:25\nCurrent Time = 19:06:26\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_test = pd.DataFrame({'tfidf_pred': tfidf_test_pred, 'pos_pred': pos_test_pred, 'num_pred': test_pred})","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:26.093711Z","iopub.execute_input":"2024-01-27T19:06:26.094110Z","iopub.status.idle":"2024-01-27T19:06:26.098941Z","shell.execute_reply.started":"2024-01-27T19:06:26.094081Z","shell.execute_reply":"2024-01-27T19:06:26.098178Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y_test_pred = cat_clf_stack.predict_proba(pred_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:26.100381Z","iopub.execute_input":"2024-01-27T19:06:26.100710Z","iopub.status.idle":"2024-01-27T19:06:26.109618Z","shell.execute_reply.started":"2024-01-27T19:06:26.100678Z","shell.execute_reply":"2024-01-27T19:06:26.108823Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame({'id': X_test_id, 'generated': y_test_pred})\nresults.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:26.110677Z","iopub.execute_input":"2024-01-27T19:06:26.111576Z","iopub.status.idle":"2024-01-27T19:06:26.122181Z","shell.execute_reply.started":"2024-01-27T19:06:26.111537Z","shell.execute_reply":"2024-01-27T19:06:26.120909Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"printime()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T19:06:26.123415Z","iopub.execute_input":"2024-01-27T19:06:26.123739Z","iopub.status.idle":"2024-01-27T19:06:26.132084Z","shell.execute_reply.started":"2024-01-27T19:06:26.123710Z","shell.execute_reply":"2024-01-27T19:06:26.130983Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Current Time = 19:06:26\n","output_type":"stream"}]}]}